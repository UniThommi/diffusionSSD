{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cfae21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dateien gefunden\n",
      "  Train: /pscratch/sd/t/tbuerger/data/optPhotonSensitiveSurface/MLFormatHomogeneousNCsZylSSD300PMTs/resum_output_0_train.hdf5\n",
      "  Val:   /pscratch/sd/t/tbuerger/data/optPhotonSensitiveSurface/MLFormatHomogeneousNCsZylSSD300PMTs/resum_output_0_validation.hdf5\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Datenpfad\n",
    "data_path = Path(\"/pscratch/sd/t/tbuerger/data/optPhotonSensitiveSurface/MLFormatHomogeneousNCsZylSSD300PMTs\")\n",
    "train_file = data_path / \"resum_output_0_train.hdf5\"\n",
    "val_file = data_path / \"resum_output_0_validation.hdf5\"\n",
    "\n",
    "# Prüfe Existenz\n",
    "assert train_file.exists(), f\"Train-File nicht gefunden: {train_file}\"\n",
    "assert val_file.exists(), f\"Val-File nicht gefunden: {val_file}\"\n",
    "\n",
    "print(f\"✓ Dateien gefunden\")\n",
    "print(f\"  Train: {train_file}\")\n",
    "print(f\"  Val:   {val_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92439e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Train Dataset ===\n",
      "Neutron Captures: 3,627,360\n",
      "Anzahl Voxel:     9,583\n",
      "Target Shape:     (3627360,)\n",
      "\n",
      "=== Validation Dataset ===\n",
      "Neutron Captures: 906,138\n",
      "\n",
      "=== Gesamt ===\n",
      "Total Captures:   4,533,498\n"
     ]
    }
   ],
   "source": [
    "# Öffne Train-File und analysiere Struktur\n",
    "with h5py.File(train_file, 'r') as f:\n",
    "    # Anzahl Neutron Captures\n",
    "    n_captures_train = len(f['phi']['xNC_mm'])\n",
    "    \n",
    "    # Anzahl Voxel\n",
    "    voxel_ids = list(f['target'].keys())\n",
    "    n_voxels = len(voxel_ids)\n",
    "    \n",
    "    # Beispiel-Voxel Shape\n",
    "    example_shape = f['target'][voxel_ids[0]].shape\n",
    "    \n",
    "    print(f\"=== Train Dataset ===\")\n",
    "    print(f\"Neutron Captures: {n_captures_train:,}\")\n",
    "    print(f\"Anzahl Voxel:     {n_voxels:,}\")\n",
    "    print(f\"Target Shape:     {example_shape}\")\n",
    "\n",
    "# Validation Dataset\n",
    "with h5py.File(val_file, 'r') as f:\n",
    "    n_captures_val = len(f['phi']['xNC_mm'])\n",
    "    print(f\"\\n=== Validation Dataset ===\")\n",
    "    print(f\"Neutron Captures: {n_captures_val:,}\")\n",
    "\n",
    "print(f\"\\n=== Gesamt ===\")\n",
    "print(f\"Total Captures:   {n_captures_train + n_captures_val:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb7f00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 10,000 von 3,627,360 Captures (0.28%)\n"
     ]
    }
   ],
   "source": [
    "# Anzahl zu sampleder Neutron Captures\n",
    "N_SAMPLE = 10_000  # Anpassbar\n",
    "\n",
    "# Stelle sicher, dass nicht mehr gesampelt wird als vorhanden\n",
    "N_SAMPLE = min(N_SAMPLE, n_captures_train)\n",
    "\n",
    "# Zufällige Indices (reproduzierbar)\n",
    "np.random.seed(42)\n",
    "sample_indices = np.random.choice(n_captures_train, size=N_SAMPLE, replace=False)\n",
    "sample_indices = np.sort(sample_indices)  # Sortieren für effizienteres HDF5-Lesen\n",
    "\n",
    "print(f\"Sampling {N_SAMPLE:,} von {n_captures_train:,} Captures ({N_SAMPLE/n_captures_train*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1010ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lade Voxel-Hits für gesampelte Captures\n",
    "voxel_hit_sums = []\n",
    "\n",
    "with h5py.File(train_file, 'r') as f:\n",
    "    for voxel_id in voxel_ids:\n",
    "        # Summiere Hits über gesampelte Captures für dieses Voxel\n",
    "        hits = f['target'][voxel_id][sample_indices]\n",
    "        total_hits = np.sum(hits)\n",
    "        voxel_hit_sums.append(total_hits)\n",
    "\n",
    "voxel_hit_sums = np.array(voxel_hit_sums)\n",
    "\n",
    "n_total_captures = 10_000_000\n",
    "n_captures_with_data = n_captures_train\n",
    "n_captures_zero_hits = n_total_captures - n_captures_with_data\n",
    "\n",
    "# Anteil der gesampleten 0-Hit-Captures\n",
    "n_zero_hits_in_sample = int(n_captures_zero_hits * (N_SAMPLE / n_total_captures))\n",
    "\n",
    "# Erweitere voxel_hit_sums: für jeden Voxel addiere die 0-Hit-Captures\n",
    "# (haben keinen Effekt auf individuelle Voxel-Sums, nur für Kontext)\n",
    "print(f\"\\nInfo: {n_captures_zero_hits:,} Captures haben 0 detektierte Photonen (nicht in HDF5)\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Histogramm mit Binning=1\n",
    "bins = np.arange(0, voxel_hit_sums.max() + 2) - 0.5  # Zentriere Bins auf Integer-Werte\n",
    "ax.hist(voxel_hit_sums, bins=bins, edgecolor='black', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Anzahl Hits pro Voxel (summiert über alle gesampleten Captures)', fontsize=12)\n",
    "ax.set_ylabel('Anzahl Voxel', fontsize=12)\n",
    "ax.set_title('Verteilung der Voxel-Hit-Counts', fontsize=14, fontweight='bold')\n",
    "textstr = (f'Anzahl gesampleter Events: {N_SAMPLE:,}\\n'\n",
    "           f'Anzahl Voxel: {n_voxels:,}\\n'\n",
    "           f'Hinweis: {n_captures_zero_hits:,} Captures mit 0 Hits nicht gesampelt')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Annotation\n",
    "textstr = f'Anzahl gesampleter Events: {N_SAMPLE:,}\\nAnzahl Voxel: {n_voxels:,}'\n",
    "ax.text(0.98, 0.98, textstr, transform=ax.transAxes, fontsize=10,\n",
    "        verticalalignment='top', horizontalalignment='right',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistik\n",
    "print(f\"\\n=== Statistik: Hits pro Voxel ===\")\n",
    "print(f\"Min:    {voxel_hit_sums.min()}\")\n",
    "print(f\"Max:    {voxel_hit_sums.max()}\")\n",
    "print(f\"Median: {np.median(voxel_hit_sums):.1f}\")\n",
    "print(f\"Mean:   {np.mean(voxel_hit_sums):.1f}\")\n",
    "print(f\"Voxel mit 0 Hits: {np.sum(voxel_hit_sums == 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c07271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne Gesamthits pro Capture\n",
    "total_hits_per_capture = []\n",
    "\n",
    "with h5py.File(train_file, 'r') as f:\n",
    "    for idx in sample_indices:\n",
    "        # Summiere Hits über alle Voxel für dieses Capture\n",
    "        capture_total = 0\n",
    "        for voxel_id in voxel_ids:\n",
    "            capture_total += f['target'][voxel_id][idx]\n",
    "        total_hits_per_capture.append(capture_total)\n",
    "\n",
    "total_hits_per_capture = np.array(total_hits_per_capture)\n",
    "\n",
    "# Füge 0-Hit-Captures hinzu\n",
    "zero_hit_captures_sampled = np.zeros(n_zero_hits_in_sample, dtype=int)\n",
    "total_hits_per_capture = np.concatenate([total_hits_per_capture, zero_hit_captures_sampled])\n",
    "\n",
    "# Update N_SAMPLE für korrekte Statistik\n",
    "N_SAMPLE_TOTAL = len(total_hits_per_capture)\n",
    "print(f\"\\nGesamt gesampelte Captures (inkl. 0-Hit): {N_SAMPLE_TOTAL:,}\")\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Histogramm\n",
    "bins = np.arange(0, total_hits_per_capture.max() + 2) - 0.5\n",
    "ax.hist(total_hits_per_capture, bins=bins, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "\n",
    "ax.set_xlabel('Gesamtzahl Voxel-Hits pro Neutron Capture', fontsize=12)\n",
    "ax.set_ylabel('Anzahl Neutron Captures', fontsize=12)\n",
    "ax.set_title('Verteilung der Gesamt-Hits pro Neutron Capture', fontsize=14, fontweight='bold')\n",
    "textstr = (f'Anzahl gesampleter Events: {N_SAMPLE_TOTAL:,}\\n'\n",
    "           f'davon {n_zero_hits_in_sample:,} mit 0 Hits\\n'\n",
    "           f'Total NC Events: {n_total_captures:,}')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Annotation\n",
    "textstr = f'Anzahl gesampleter Events: {N_SAMPLE:,}'\n",
    "ax.text(0.98, 0.98, textstr, transform=ax.transAxes, fontsize=10,\n",
    "        verticalalignment='top', horizontalalignment='right',\n",
    "        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistik\n",
    "print(f\"\\n=== Statistik: Hits pro Neutron Capture ===\")\n",
    "print(f\"Min:    {total_hits_per_capture.min()}\")\n",
    "print(f\"Max:    {total_hits_per_capture.max()}\")\n",
    "print(f\"Median: {np.median(total_hits_per_capture):.1f}\")\n",
    "print(f\"Mean:   {np.mean(total_hits_per_capture):.1f}\")\n",
    "print(f\"Captures mit 0 Hits: {np.sum(total_hits_per_capture == 0)} ({np.sum(total_hits_per_capture == 0)/N_SAMPLE_TOTAL*100:.2f}%)\")\n",
    "print(f\"  davon {n_zero_hits_in_sample:,} nicht in HDF5 (keine Photonen detektiert)\")\n",
    "print(f\"  und {np.sum(total_hits_per_capture == 0) - n_zero_hits_in_sample:,} in HDF5 mit 0 zugeordneten Hits\")\n",
    "\n",
    "# Quantile\n",
    "print(f\"\\nQuantile:\")\n",
    "for q in [0.25, 0.5, 0.75, 0.90, 0.95, 0.99]:\n",
    "    print(f\"  {q*100:5.1f}%: {np.quantile(total_hits_per_capture, q):.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
